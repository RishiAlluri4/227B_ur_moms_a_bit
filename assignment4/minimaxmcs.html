<html>

<!--=======================================================================-->

<head>
  <title>ur_moms_a_bit</title>
  <script type='text/javascript' src='/epilog/javascript/epilog.js'></script>
  <script type='text/javascript' src='../javascript/localstorage.js'></script>
  <script type='text/javascript' src='../interpreter/general.js'></script>
  <script type='text/javascript'>
    //==============================================================================
    // Customization
    //==============================================================================

    var manager = 'manager';
    var player = 'ur_moms_a_bit';

    //==============================================================================
    // minimaxmcs.js
    //==============================================================================

    var role = 'robot';
    var rules = [];
    var startclock = 10;
    var playclock = 10;

    var library = [];
    var roles = [];
    var state = [];
    // memoization
    var memo = {};

    //==============================================================================

    function ping() {
        return 'ready'
    }

    function start(r,rs,sc,pc) {
        role = r;
        rules = rs.slice(1);
        startclock = numberize(sc);
        playclock = numberize(pc);
        library = definemorerules([],rs.slice(1));
        roles = findroles(library);
        state = findinits(library);
        memo = {};
        return 'ready';
    }

    function play(move) {
        if (move!==nil) {
            state = simulate(move,state,library);
        }
        if (findcontrol(state,library)!==role) {
            return false;
        }
        // Testing efficiency
        return playminimaxmcs(role);
    }

    function stop(move) {
        return false;
    }

    function abort() {
        return false;
    }

    var nodes = 0;
    var terminals = 0;
    var elapsed = 0;
    var mcsDepth = 0;

    function playminimaxmcs(role) {
        var actions = shuffle(findlegals(state,library));
        if (actions.length===0) {
            return false;
        }
        if (actions.length===1) {
            return actions[0];
        }
        var action = actions[0];
        var score = 0;
        var alpha = -Infinity;  
        var beta = Infinity;
        var maxDepth = 2;
        nodes = 0;
        for (var i=0; i<actions.length; i++) {
            var newstate = simulate(actions[i], state, library);
            var newscore = minimaxmcs(role, newstate, alpha, beta, maxDepth);
            if (newscore===100) {
                return actions[i];
            }
            if (newscore>score) {
                action = actions[i]; 
                score = newscore;
            }
        }
        return action;
    }

    function testminimaxdepth(role, state, alpha, beta, maxDepth) {
        nodes = 0;
        terminals = 0;
        var beg = performance.now();
        var result = minimaxdepth(role,state, alpha, beta, maxDepth);
        var end = performance.now();
        elapsed = Math.round(end-beg);
        console.log('Elapsed time: ' + elapsed + ' ms');
        return result;
    }

    function mobility(state) {
        var actions = findlegals(state,library);
        var feasibles = findactions(library);
        return (actions.length/feasibles.length * 100);
    }

    function focus(state) {
        var actions = findlegals(state,library);
        var feasibles = findactions(library);
        return (100 - actions.length/feasibles.length * 100);
    }

    // Mobility eval function
    function mobilityEval(state) {
        var active = findcontrol(state,library);
        if (active===role) {
            return mobility(state);
        }
        return focus(state);
    }

    // Pessimistic evaluation function
    function pessimisticEval(state) {  
        if (findterminalp(state,library)) {
            return findreward(role,state,library)*1;
        }
        return 0;
    }

    // Intermediate evaluation function
    function intermediateEval(state) {
        return findreward(role,state,library)*1;
    }

    // Combined evaluation function that is a weighted combination of other eval functions
    // TODO can maybe add memoization for eval functions
    function eval(state) {
        pessWeight = 0;
        intermediateWeight = 1;
        mobilityWeight = 0;
        evaluation = (pessWeight * pessimisticEval(state)) + (intermediateWeight * intermediateEval(state)) + (mobilityWeight * mobilityEval(state));
        return evaluation;
    }

    function montecarlo(state, count) {
        var total = 0;
        // For testing
        mcsDepth = 0;
        for (var i = 0; i < count; i++) {
            total += depthcharge(state);
            //total = Number(total) + Number(depthchargeval);
        }
        // console.log(state, total, mcsDepth, total/count);
        return total/count;
    }

    function randomindex(n) {
        return Math.floor(Math.random()*n);
    }

    function depthcharge(state) {
        if (findterminalp(state, library)) {
            return findreward(role,state,library)*1;
        }
        var actions = findlegals(state,library);
        var best = randomindex(actions.length);
        var newstate = simulate(actions[best],state,library);
        mcsDepth += 1;
        return depthcharge(newstate);
    }

    function minimaxmcs(role, state, alpha, beta, maxDepth) {
        nodes = nodes + 1;
        // use state for memo key
        var stateKey = JSON.stringify(state);
        if (stateKey in memo) {
            return memo[stateKey];
        }
        if (findterminalp(state,library)) {
            terminals = terminals + 1;
            var reward = findreward(role,state,library)*1;
            memo[stateKey] = reward;  
            return reward;
        }
        if (maxDepth <= 0) {
            // Maybe we can somehow dynamically change count
            var count = 10
            return montecarlo(state, count);
        }
        var active = findcontrol(state,library);
        if (active===role) {
            var maxScore = maximize(active, role, state, alpha, beta, maxDepth - 1);
            return maxScore;
        }
        var minScore = minimize(active, role, state, alpha, beta, maxDepth - 1);
        return minScore;
    }

    function maximize(active, role, state, alpha, beta, maxDepth) {
        var actions = findlegals(state,library);
        if (actions.length===0) {
            return 0;
        }
        var score = 0;
        for (var i=0; i<actions.length; i++) {
            var newstate = simulate(actions[i],state,library);
            var newscore = minimaxmcs(role, newstate, alpha, beta, maxDepth);
            score = Math.max(score, newscore); 
            if (score===100) {
                return 100;
            }
            alpha = Math.max(alpha, score);
            if (beta <= alpha) {
                break;
            }
        }
        return score;
    }

    function minimize(active, role, state, alpha, beta, maxDepth) {
        var actions = findlegals(state,library);
        if (actions.length===0) {
            return 0;
        }
        var score = 100;
        for (var i=0; i<actions.length; i++) {
            var newstate = simulate(actions[i],state,library);
            var newscore = minimaxmcs(role, newstate, alpha, beta, maxDepth);
            score = Math.min(score, newscore);
            if (score===0) {
                return 0;
            }
            beta = Math.min(beta, score);
            if (beta <= alpha) {
                break;
            }
        }
        return score;
    }

    function shuffle (array) {
        for (var i = array.length-1; i>0; i--) {
            var j = Math.floor(Math.random() * (i + 1));
            var temp = array[i];
            array[i] = array[j];
            array[j] = temp;
        }
        return array;
    }

    //==============================================================================
    // End of player code
    //==============================================================================
  </script>
</head>
<!--
    TODO - need to change: Our player this week uses the minimax algorithm discussed in class with a few optimizations which improve runtime. 
    The minimax algorithm simulates the possible moves in a game’s tree to determine the best strategy by minimizing the potential loss. 
    It evaluates all outcomes of all legal moves while predicting possible opponent moves and creates path with the most advantageous outcome. 
    
    In single player games, this means the agent maximizes the value of each of its actions in order to achieve the highest score. 
    In multiplayer games, the agent performs the minimax algorithm to optimize its decisions based on the presumption that the opponent 
    will choose moves aimed at minimizing our score. 
    
    To optimize the runtime of our agent, we used memoization within the minimax algorithm to prevent redundant calculations 
    by storing results of rewards for each unique pair of role and state and returning the stored values if possible. 

    Additionally, we implemented alpha-beta pruning in the minimax, maximize and minimize functions. 
    The alpha variable represents the greatest score of an already explored option along the path to the root for the maximizer; 
    conversely, the beta represents the lowest already explored option for the minimizer. 
    By updating these values every time a node is evaluated and maintaining accurate bounds, 
    the algorithm can skip branches of the state space tree that have no chance of changing the final minimum or maximum.

    In an ideal scenario where all of the best moves are explored first within the tree, alpha-beta pruning can reduce the complexity of the minimax algorithm 
    from O(b^d) to O(b^(d/2)) where ‘b’ is the branching factor of the tree and ‘d’ is the depth of the tree. 

    Even in a scenario that is not completely optimal, the greatly increases the efficiency of the algorithm and 
    significantly reduces the portion of the state space tree that must be explored.  
    -->

<!--=======================================================================-->

<body bgcolor='#000000' onload='doinitialize()'>
  <center>
    <table width='720' cellspacing='0' cellpadding='40' bgcolor='#ffffff'>
      <tr>
        <td>

<!--=======================================================================-->

<center>
  <table width='640' cellpadding='0'>
    <tr>
      <td width='180' align='center' valign='center'>
        <img width='130' src='http://gamemaster.stanford.edu/images/ggp.jpg'/>
      </td>
      <td align='center'>
        <span style='font-size:18pt'>&nbsp;</span>
        <span style='font-size:28pt'>Ur Moms A Bit</span><br/>
        <span style='font-size:22pt'>&#x1F449; &#x1F469; &#x1F170; &#x1F479;</span>
      </td>
      <td width='180' align='center' style='color:#000066;font-size:18px'>
        <i>General<br/>Game<br/>Playing</i>
      </td>
    </tr>
  </table>
</center>

<!--=======================================================================-->

<br/>
<table width='640' cellpadding='8' cellspacing='0' bgcolor='#f4f8f8' border='1'>
  <tr height='40'>
     <td align='center'>
<table style='color:#000066;font-size:18px'>
  <tr>
    <td>
Protocol: localstorage<br/>
Metagamer: none<br/>
Strategy: minimax+memo+abpruning+depthmcs<br/>
Identifier: <span id='player'>ur_moms_a_bit</span> <img src="http://gamemaster.stanford.edu/images/pencil.gif" onclick='doplayer()'/>
    </td>
  </tr>
</table>
    </td>
  </tr>
</table>
<br/>

<!--=======================================================================-->

<center>
  <br/>
  <textarea id='transcript' style='font-family:courier' rows='30' cols='80' readonly></textarea>
</center>

<!--=======================================================================-->

        </td>
      </tr>
    </table>
  </center>
</body>

<!--=======================================================================-->

</html>